stages:
  # --- STAGE 0: COMMON BASE (Deduplication) ---
  # Rimuove i duplicati mantenendo la struttura train/val/test
  deduplicate:
    cmd: python src/preprocessing/deduplicate.py --input data/raw --output data/deduplicated
    deps:
      - data/raw
      - src/preprocessing/deduplicate.py
    outs:
      - data/deduplicated

  # =======================================================
  # PIPELINE 1: BASELINE (Raw Clean Data)
  # =======================================================
  train_p1:
    foreach: [effnet_v2_s, convnext]
    do:
      # Uso: Train pulito, Valid pulito
      cmd: python -m src.train --model ${item} --train data/deduplicated/train --val data/deduplicated/valid --out models/p1/${item} --batch 16 --epochs 2
      deps:
        - data/deduplicated/train
        - data/deduplicated/valid
        - src/train.py
      outs:
        - models/p1/${item}/model.pth
        - models/p1/${item}/loss_plot.png
        - models/p1/${item}/history.json

  evaluate_p1:
    foreach: [effnet_v2_s, convnext]
    do:
      # Valutazione finale su Test Set pulito
      cmd: python -m src.evaluate --model ${item} --weights models/p1/${item}/model.pth --data data/deduplicated/test --out models/p1/${item}
      deps:
        - data/deduplicated/test
        - src/evaluate.py
        - models/p1/${item}/model.pth
      metrics:
        - models/p1/${item}/metrics.json:
            cache: false
      plots:
        - models/p1/${item}/confusion_matrix.png:
            cache: false

  # =======================================================
  # PIPELINE 2: DATA AUGMENTATION
  # =======================================================
  augment_p2:
    # Aumentiamo SOLO il train set
    cmd: python src/preprocessing/augment.py --input data/deduplicated/train --output data/augmented/train
    deps:
      - data/deduplicated/train
      - src/preprocessing/augment.py
    outs:
      - data/augmented/train

  train_p2:
    foreach: [effnet_v2_s, convnext]
    do:
      # Uso: Train AUMENTATO, ma Valid PULITO (fondamentale per controllo reale)
      cmd: python -m src.train --model ${item} --train data/augmented/train --val data/deduplicated/valid --out models/p2/${item} --batch 16 --epochs 20
      deps:
        - data/augmented/train
        - data/deduplicated/valid
        - src/train.py
      outs:
        - models/p2/${item}/model.pth
        - models/p2/${item}/loss_plot.png
        - models/p2/${item}/history.json

  evaluate_p2:
    foreach: [effnet_v2_s, convnext]
    do:
      cmd: python -m src.evaluate --model ${item} --weights models/p2/${item}/model.pth --data data/deduplicated/test --out models/p2/${item}
      deps:
        - data/deduplicated/test
        - src/evaluate.py
        - models/p2/${item}/model.pth
      metrics:
        - models/p2/${item}/metrics.json:
            cache: false
      plots:
        - models/p2/${item}/confusion_matrix.png:
            cache: false

  # =======================================================
  # PIPELINE 3: BALANCING
  # =======================================================
  balance_p3:
    # Bilanciamo solo il train set
    cmd: python src/preprocessing/balance.py --input data/deduplicated/train --output data/balanced/train
    deps:
      - data/deduplicated/train
      - src/preprocessing/balance.py
    outs:
      - data/balanced/train

  train_p3:
    foreach: [effnet_v2_s, convnext]
    do:
      # Uso: Train BILANCIATO, Valid PULITO
      # Nota: Ho rimosso --finetune True perchÃ© lo gestisci tu nel codice o se lo vuoi aggiungere come flag in train.py
      cmd: python -m src.train --model ${item} --train data/balanced/train --val data/deduplicated/valid --out models/p3/${item} --batch 16 --epochs 20
      deps:
        - data/balanced/train
        - data/deduplicated/valid
        - src/train.py
      outs:
        - models/p3/${item}/model.pth
        - models/p3/${item}/loss_plot.png
        - models/p3/${item}/history.json

  evaluate_p3:
    foreach: [effnet_v2_s, convnext]
    do:
      cmd: python -m src.evaluate --model ${item} --weights models/p3/${item}/model.pth --data data/deduplicated/test --out models/p3/${item}
      deps:
        - data/deduplicated/test
        - src/evaluate.py
        - models/p3/${item}/model.pth
      metrics:
        - models/p3/${item}/metrics.json:
            cache: false
      plots:
        - models/p3/${item}/confusion_matrix.png:
            cache: false

  # =======================================================
  # PIPELINE 4: HYBRID (Augment -> Balance)
  # =======================================================
  augment_p4:
    # Step 1: Augmentation del train originale
    cmd: python src/preprocessing/augment.py --input data/deduplicated/train --output data/tmp/p4_aug
    deps:
      - data/deduplicated/train
      - src/preprocessing/augment.py
    outs:
      - data/tmp/p4_aug

  balance_p4:
    # Step 2: Balancing sul dataset aumentato
    cmd: python src/preprocessing/balance.py --input data/tmp/p4_aug --output data/hybrid/train
    deps:
      - data/tmp/p4_aug
      - src/preprocessing/balance.py
    outs:
      - data/hybrid/train

  train_p4:
    foreach: [effnet_v2_s, convnext]
    do:
      # Uso: Train IBRIDO, Valid PULITO
      cmd: python -m src.train --model ${item} --train data/hybrid/train --val data/deduplicated/valid --out models/p4/${item} --batch 16 --epochs 20
      deps:
        - data/hybrid/train
        - data/deduplicated/valid
        - src/train.py
      outs:
        - models/p4/${item}/model.pth
        - models/p4/${item}/loss_plot.png
        - models/p4/${item}/history.json

  evaluate_p4:
    foreach: [effnet_v2_s, convnext]
    do:
      cmd: python -m src.evaluate --model ${item} --weights models/p4/${item}/model.pth --data data/deduplicated/test --out models/p4/${item}
      deps:
        - data/deduplicated/test
        - src/evaluate.py
        - models/p4/${item}/model.pth
      metrics:
        - models/p4/${item}/metrics.json:
            cache: false
      plots:
        - models/p4/${item}/confusion_matrix.png:
            cache: false